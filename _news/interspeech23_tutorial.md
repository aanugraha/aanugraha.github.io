---
layout: post
title: Our team provided a tutorial entitled "Foundations, Extensions and Applications of Statistical Multichannel Speech Separation Models" at Interspeech 2023.
date: 2023-08-20 14:00:00+0100
inline: false
---

Our team provided a tutorial entitled <a href="https://interspeech2023.org/tutorials/#toggle-id-5">"Foundations, Extensions and Applications of Statistical Multichannel Speech Separation Models"</a> at <a href="https://interspeech2023.org/">Interspeech 2023</a>.

<blockquote>
This tutorial aims to enlighten audio and speech researchers who are interested in source separation and speech enhancement on how to formulate a physics-aware probabilistic model that explicitly stands for the generative process of observed audio signals (direct problem) and how to derive its maximum likelihood estimator (inverse problem) in a principled manner. Under mismatched conditions and/or with less training data, the separation performance of supervised methods might be degraded drastically in the real world, as is often the case with deep learning-based methods that work well in controlled benchmarks. We show first that the state-of-the-art blind source separation (BSS) methods can work comparably or even better in the real world and play avital role for drawing the full potential of deep learning-based methods. Secondly, this tutorial introduces how to develop an augmented reality (AR) application for smart glasses with real-time speech enhancement and recognition of target speakers.
</blockquote>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/interspeech_tutorial.jpg" data-zoomable>
    </div>
</div>